#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
NNC: A portable implementation of constructed neural networks
\end_layout

\begin_layout Author
Ioannis G.
 Tsoulos
\begin_inset Formula $^{(1)}$
\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
Corresponding author.
 Email: itsoulos@teiep.gr
\end_layout

\end_inset


\end_layout

\begin_layout Date
\begin_inset Formula $^{(1)}$
\end_inset

Department of Computer Engineering, School of Applied Technology, Technological
 Educational Institute of Epirus, 47100 Arta, Greece
\end_layout

\begin_layout Abstract
A portable software that implements constructed neural networks with the
 utilization of Grammatical Evolution is presented here.
 The introduced software is used for classification problems, regression
 problems as well as to solve differential equations.
 The software is compiled with the QT library in order to be portable in
 any operating system.
 The usage of the software is demonstrated on a series of classification
 problems as well as on some differential equations.
\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
Neural networks are well - established parametric tools 
\begin_inset CommandInset citation
LatexCommand cite
key "neural1,neural2"

\end_inset

, used with success in many areas such as pattern recognition 
\begin_inset CommandInset citation
LatexCommand cite
key "key3"

\end_inset

, signal processing 
\begin_inset CommandInset citation
LatexCommand cite
key "key4"

\end_inset

, astronomy 
\begin_inset CommandInset citation
LatexCommand cite
key "key5"

\end_inset

, solution of ordinary and partial differential equations 
\begin_inset CommandInset citation
LatexCommand cite
key "key6"

\end_inset

 etc.
 A neural network can be expressed as a function 
\begin_inset Formula $N(\overrightarrow{x},\overrightarrow{w})$
\end_inset

, where
\begin_inset Formula $\overrightarrow{x}$
\end_inset

 is the input vector and 
\begin_inset Formula $\overrightarrow{w}$
\end_inset

 is the vector of the parameters to be estimated.
 The latest is usually called weight vector.
 The modification of the vector of parameters (neural network training)
 is implemented by minimizing the following equation (also named error function)
:
\begin_inset Formula 
\begin{equation}
E\left(N\left(\overrightarrow{x},\overrightarrow{w}\right)\right)=\sum_{i=1}^{M}\left(N\left(\overrightarrow{x}_{i},\overrightarrow{w}\right)-y_{i}\right)^{2}\label{eq:eq1}
\end{equation}

\end_inset

In the above equation the set 
\begin_inset Formula $\left(\overrightarrow{x_{i}},y_{i}\right),\ i=1,...,M$
\end_inset

 is the data used to train the neural network.
\end_layout

\begin_layout Section
Method description 
\end_layout

\begin_layout Section
Implementation 
\end_layout

\begin_layout Section
Using the software 
\end_layout

\begin_layout Subsection
Command line options 
\end_layout

\begin_layout Standard
The available command line options of the main executable NNC are:
\end_layout

\begin_layout Enumerate
-h.
 This options prints an information help screen and the program terminates.
\end_layout

\begin_layout Enumerate
-p 
\series bold
filename
\series default
.
 This parameter determines the path of the objective problem.
 If the value of the parameter kind is 
\emph on
neural
\emph default
, then this parameter determines the train file for classification or regression.
 Otherwise, this parameter determines the shared library with the differential
 equation to be solved.
\end_layout

\begin_layout Enumerate
-t 
\series bold
filename
\series default
.
 The string parameter filename defines the test file for the neural network.
 This parameter is valid only if kind has the value of 
\emph on
neural
\emph default
.
\end_layout

\begin_layout Enumerate
-c 
\series bold
count
\series default
.
 The integer value count specifies the amount of chromosomes used in the
 genetic population.
 The default value for this parameter is 500.
\end_layout

\begin_layout Enumerate
-l 
\series bold
length
\series default
.
 The integer parameter length determines the size of each chromosome.
 The default value is 200.
\end_layout

\begin_layout Enumerate
-s 
\series bold
rate
\series default
.
 The float parameter rate specifies the selection rate used in the genetic
 algorithm.
 The default value is 0.1 (10%)
\end_layout

\begin_layout Enumerate
-m 
\series bold
rate
\series default
.
 The float parameter rate stands for the mutation rate in the genetic algorithm.
 The default value is 0.05 (5%)
\end_layout

\begin_layout Enumerate
-r 
\series bold
seed
\series default
.
 The integer parameter seed determines the number used as a random seed
 in random generators.
 The default value is 1
\end_layout

\begin_layout Enumerate
-k 
\series bold
kind
\series default
.
 The string parameter kind determines the usage of the constructed neural
 network.
 Accepted values are
\end_layout

\begin_deeper
\begin_layout Enumerate
neural, for regression or classification problems.
\end_layout

\begin_layout Enumerate
ode, for solving ordinary differential equations.
\end_layout

\begin_layout Enumerate
pde, for solving elliptical partial differential equations.
\end_layout

\begin_layout Enumerate
sode, for solving systems of ordinary differential equations.
\end_layout

\end_deeper
\begin_layout Enumerate
-o 
\series bold
filename
\series default
.
 The string parameter filename sets the output file of the execution.
 The format of the output file depends on the parameter kind.
\end_layout

\begin_layout Enumerate
-n 
\series bold
gens
\series default
.
 The integer parameter gens determines the maximum allowed number of generations.
 The default value is 500.
\end_layout

\begin_layout Enumerate
-g 
\series bold
gens
\series default
.
 The integer parameter gens specifies the amount of generations that will
 be executed before the local search step of the genetic algorithm.
 The default value for this parameter is 50.
\end_layout

\begin_layout Enumerate
-d 
\series bold
count
\series default
.
 The integer parameter count specifies the amount of chromosomes that will
 take part into local search step of the genetic algorithm.
 The default value for this parameter is 20.
\end_layout

\begin_layout Subsection
Problem formulation
\end_layout

\begin_layout Standard
Example of formulation for every kind.
\end_layout

\begin_layout Subsection
Experiments
\end_layout

\begin_layout Section
Future developments
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "neural1"

\end_inset

C.
 Bishop, Neural Networks for Pattern Recognition, Oxford University Press,
 1995.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "neural2"

\end_inset

G.
 Cybenko, Approximation by superpositions of a sigmoidal function, Mathematics
 of Control Signals and Systems 2, pp.
 303-314, 1989.
\end_layout

\end_body
\end_document
